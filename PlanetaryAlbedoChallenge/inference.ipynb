{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "# plotting\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# allow \"direct\" plotting pandas and xarray just in case\n",
    "import hvplot.pandas  # noqa\n",
    "import hvplot.xarray  # noqa\n",
    "pd.options.plotting.backend = 'holoviews'\n",
    "\n",
    "# setup plotting libs\n",
    "hv.extension('bokeh', 'matplotlib')\n",
    "%matplotlib inline\n",
    "\n",
    "# not necessary but why not\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "# repeatability\n",
    "np.random.seed(123)\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and show raw data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "raw_data = {k: pd.read_csv('./Data/' + f, sep=',', header=None) for k, f in \n",
    "                [('albedo', 'Albedo.csv'), \n",
    "                 ('a', 'Element_A_Map.csv'), ('b', 'Element_B_Map.csv'),\n",
    "                 ('c', 'Element_C_Map.csv'), ('d', 'Element_D_Map.csv')]\n",
    "           }\n",
    "for r in raw_data.values():\n",
    "    r.index.name='y'\n",
    "    r.columns.name='x'\n",
    "    r.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = xr.Dataset(raw_data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "plot_image = partial(hv.Image, kdims=['x', 'y'])\n",
    "\n",
    "def layout_vars(foo):\n",
    "    return lambda ds: hv.NdLayout({v: foo(ds[v]) for v in ds}, kdims=['variable']).cols(2)\n",
    "\n",
    "layout_vars(plot_image)(data).opts(opts.Image(width=len(data.x), height=len(data.y), colorbar=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_diag_vars(pair, solo):\n",
    "    return lambda tidy: hv.GridSpace({\n",
    "        (a,b): pair(tidy, [a, b]) if a!=b else solo(tidy, a)\n",
    "        for a in tidy.columns\n",
    "        for b in tidy.columns\n",
    "    })     \n",
    "\n",
    "def map_datasets(foo, kdims=None):\n",
    "    return lambda datasets: hv.HoloMap({\n",
    "        k: foo(ds)\n",
    "        for k, ds in datasets.items()\n",
    "    }, kdims=kdims).collate()\n",
    "\n",
    "def my_hex(ds):\n",
    "    return grid_diag_vars( \n",
    "        lambda ds, kdims: hv.Overlay([hv.HexTiles(ds, kdims)]),\n",
    "        lambda ds, a: hv.Overlay([hv.Histogram(np.histogram(ds[a].values, bins=20))])\n",
    "    )(ds).opts(\n",
    "        opts.HexTiles(colorbar=True, logz=True, gridsize=20),\n",
    "        opts.Overlay(width=180, height=180)\n",
    "    )\n",
    "\n",
    "my_hex(data.to_dataframe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layout_datasets(foo, kdims=None):\n",
    "    return lambda datasets: hv.NdLayout({\n",
    "        k: foo(ds)\n",
    "        for k, ds in datasets.items()\n",
    "    }, kdims=kdims)\n",
    "    \n",
    "\n",
    "def map_variables(foo):\n",
    "    return lambda ds: hv.HoloMap({\n",
    "        k: foo(ds[k])\n",
    "        for k in ds\n",
    "    }, kdims='variables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model_u = tf.keras.models.load_model('./unet.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model_u, show_shapes=True, rankdir='LR', dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH = 1\n",
    "\n",
    "\n",
    "def prep_u(ds, pad=0):\n",
    "    X = ds.albedo.transpose().data\n",
    "    X = np.pad(X, [(0,), (pad,)], 'wrap')\n",
    "    X = np.pad(X, [(pad,), (0,)], 'edge')[None, ..., None]\n",
    "    X /= 100\n",
    "    Y = ds[list('abcd')].to_array().transpose().data[None, ...]\n",
    "    Y /= 100\n",
    "    return X.repeat(BATCH, axis=0), Y.repeat(BATCH, axis=0)\n",
    "print([x.shape for x in prep_u(data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_data = data.copy()\n",
    "X, _ = prep_u(data)\n",
    "pred_u = model_u.predict(X)[0]*100\n",
    "print(pred_u.shape)\n",
    "for i, k in enumerate('abcd'):\n",
    "    prediction = pred_u[..., i].transpose()\n",
    "    u_data[k] = (('y', 'x'), prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Layout(\n",
    "    [hv.HexTiles(data.to_dataframe(), ['albedo', element]) * hv.Points(u_data.to_dataframe().sample(1000), ['albedo', element]) \n",
    "         for element in 'abcd']\n",
    ").opts(\n",
    "    opts.HexTiles(colorbar=True, logz=True, gridsize=20),\n",
    "    opts.Points(color='white')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_datasets(layout_vars(plot_image), 'model')\\\n",
    "({'original': data, 'unet': u_data})\\\n",
    ".opts(opts.Image(width=len(data.x), height=len(data.y), colorbar=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deliverables\n",
    "\n",
    "* Google Colab Jupyter Notebook showing your solution along with the final model score More details regarding the format of the notebook can be found in the sample Google Colab notebook provided for this challenge.  \n",
    "* A txt file for each element containing your predictions on the test data. Format should be: x_coordinate, y_coordinate, predicted_value. Put name of element in file. An example is provided.\n",
    "* The final trained model including the model architecture and the trained weights (For example: HDF5 file, .pb file, .pt, .sav file, etc.). You are free to choose Machine Learning Framework of your choice.\n",
    "* Example submissions can be found https://drive.google.com/drive/folders/1EsqNLc5DzCsaJuvSTYF85gMS5PTVell4?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vx_min, vx_max, vy_min, vy_max, x_max, y_max = [300, 430, 140, 270, 720, 360]\n",
    "test_data = u_data.where(\n",
    "    np.logical_and(\n",
    "        np.logical_and(data.x >= vx_min, data.x < vx_max),\n",
    "        np.logical_and(data.y >= vy_min, data.y < vy_max)\n",
    "    )\n",
    ").dropna('x', 'all').dropna('y', 'all')\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = test_data.to_dataframe().reset_index()\n",
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in 'abcd':\n",
    "    out_df[['x', 'y', e]].to_csv(f'./element_{e.upper()}_predictions.txt', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_score = pd.DataFrame([\n",
    "    {\n",
    "        'score': mean_squared_error(\n",
    "            prep_u(ds)[1][0, ..., i]*100,\n",
    "            model_u.predict(prep_u(ds)[0])[0, ..., i]*100\n",
    "        ),\n",
    "        'dataset': ds_k,\n",
    "        'element': el,\n",
    "        'model': 'unet'\n",
    "    }\n",
    "    for ds_k, ds in [('test', test_data), ('all', data)]\n",
    "    for i, el in enumerate('abcd')\n",
    "])\n",
    "u_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum of MSE on all and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_score.groupby('dataset').sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
